{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJehY9axkKlpiWUoAQY0bh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GordonGustafson/cuda-stuff/blob/main/leetgpu/convolution_2d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAkGK5pXZw6m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.cpp_extension import load_inline\n",
        "\n",
        "!pip install Ninja"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src = \"\"\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <torch/extension.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
        "\n",
        "#define BLOCK_SIZE 32\n",
        "#define MAX_KERNEL_AREA (16 * 1024)\n",
        "#define cdiv(dividend, divisor) ((dividend + divisor - 1) / dividend)\n",
        "\n",
        "__constant__ float kernel_constant[MAX_KERNEL_AREA];\n",
        "\n",
        "__global__ void convolution_2d(float const* const input,\n",
        "                               float* const output,\n",
        "                               int const input_rows,\n",
        "                               int const input_cols,\n",
        "                               int const kernel_rows,\n",
        "                               int const kernel_cols) {\n",
        "    int const row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int const col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    int const output_rows = input_rows - kernel_rows + 1;\n",
        "    int const output_cols = input_cols - kernel_cols + 1;\n",
        "\n",
        "    __shared__ float input_tile_shared[BLOCK_SIZE][BLOCK_SIZE];\n",
        "\n",
        "    if (row < input_rows && col < input_cols) {\n",
        "        input_tile_shared[threadIdx.y][threadIdx.x] = input[row * input_cols + col];\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if (row < output_rows && col < output_cols) {\n",
        "        float result = 0.0f;\n",
        "        for (int kernel_row = 0; kernel_row < kernel_rows; kernel_row++) {\n",
        "            for (int kernel_col = 0; kernel_col < kernel_cols; kernel_col++) {\n",
        "                int const row_within_block = threadIdx.y + kernel_row;\n",
        "                int const col_within_block = threadIdx.x + kernel_col;\n",
        "                if (row_within_block < BLOCK_SIZE && col_within_block < BLOCK_SIZE) {\n",
        "                    result += input_tile_shared[row_within_block][col_within_block] * kernel_constant[kernel_row * kernel_cols + kernel_col];\n",
        "                } else {\n",
        "                    // If we're lucky this will be in cache due to other blocks having read it recently.\n",
        "                    result += input[(row + kernel_row) * input_cols + col + kernel_col] * kernel_constant[kernel_row * kernel_cols + kernel_col];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        output[row * output_cols + col] = result;\n",
        "    }\n",
        "}\n",
        "\n",
        "// input, kernel, output are device pointers\n",
        "void conv2d(const float* input, const float* kernel, float* output,\n",
        "           int input_rows, int input_cols, int kernel_rows, int kernel_cols) {\n",
        "    int const kernel_area = kernel_rows * kernel_cols;\n",
        "    if (kernel_area > MAX_KERNEL_AREA) {\n",
        "        printf(\"Kernel is larger than MAX_KERNEL_AREA constant\");\n",
        "        return;\n",
        "    }\n",
        "    cudaMemcpyToSymbol(kernel_constant, kernel, kernel_area * sizeof(float));\n",
        "\n",
        "    dim3 const threadsPerBlock = dim3(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 const blocksPerGrid = dim3(cdiv(input_rows, threadsPerBlock.y),\n",
        "                                    cdiv(input_cols, threadsPerBlock.x));\n",
        "    convolution_2d<<<blocksPerGrid, threadsPerBlock>>>(input, output, input_rows, input_cols, kernel_rows, kernel_cols);\n",
        "}\n",
        "\n",
        "torch::Tensor conv2d_torch_tensors(torch::Tensor input, torch::Tensor filter) {\n",
        "    CHECK_INPUT(input);\n",
        "    CHECK_INPUT(filter);\n",
        "\n",
        "    int const input_width = input.size(0);\n",
        "    int const input_height = input.size(1);\n",
        "    int const filter_width = filter.size(0);\n",
        "    int const filter_height = filter.size(1);\n",
        "    torch::Tensor output = torch::empty({input_width - filter_width + 1, input_height - filter_height + 1}, input.options());\n",
        "    conv2d(input.data_ptr<float>(), filter.data_ptr<float>(), output.data_ptr<float>(), input_height, input_width, filter_height, filter_width);\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return output;\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cpp_src = \"torch::Tensor conv2d_torch_tensors(torch::Tensor input, torch::Tensor filter);\"\n",
        "functions = ['conv2d_torch_tensors']\n",
        "\n",
        "module = load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=functions, extra_cuda_cflags=[\"-O2\"], verbose=True, name=\"inline_ext\")"
      ],
      "metadata": {
        "id": "vAxvjUmMdIhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.ones((128, 128), dtype=torch.float32, device='cuda')\n",
        "filter = torch.ones((5, 5), dtype=torch.float32, device='cuda')\n",
        "result = module.conv2d_torch_tensors(input, filter)\n",
        "# torch.set_printoptions(profile=\"full\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "fgvOKg2AjIwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.shape)"
      ],
      "metadata": {
        "id": "0aSBo1krZB5c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}